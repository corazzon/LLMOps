## Chapter04

## 참고문헌

* Chang, Ernie, Matteo Paltenghi, Yang Li, et al. 2024.
  **[Scaling Parameter-Constrained Language Models with Quality Data](https://arxiv.org/abs/2410.03083)**. arXiv.

* Chardet. n.d.
  **[Chardet: The Universal Character Encoding Detector](https://chardet.readthedocs.io/en/latest/usage.html)**.

* Codd, E. F. 1970.
  **[A Relational Model of Data for Large Shared Data Banks](https://dl.acm.org/doi/10.1145/362384.362685)**. *Communications of the ACM*, 13(6): 377–387.

* Common Crawl. n.d.
  **[Common Crawl](https://commoncrawl.org/)**.

* Dodge, Jesse, Maarten Sap, Ana Marasović, et al. 2021.
  **[Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus](https://arxiv.org/abs/2104.08758)**. arXiv.

* Gao, Yunfan, Yun Xiong, Xinyu Gao, et al. 2024.
  **[Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997)**. arXiv.

* Hoffmann, Jordan, Sebastian Borgeaud, Arthur Mensch, et al. 2022.
  **[Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556)**. arXiv.

* Kaplan, Jared, Sam McCandlish, Tom Henighan, et al. 2020.
  **[Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)**. arXiv.

* Lee, Cinoo, Kristina Gligorić, Pratyusha Ria Kalluri, et al. 2024.
  **[People Who Share Encounters with Racism Are Silenced Online by Humans and Machines, but a Guideline-Reframing Intervention Holds Promise](https://www.pnas.org/doi/10.1073/pnas.2322764121)**. *PNAS*, 121(38).

* LlamaIndex. n.d.
  **[Vector Stores](https://developers.llamaindex.ai/python/framework/module_guides/storing/vector_stores/)**.

* Ma, Yingwei, Yue Liu, Yue Yu, et al. 2023.
  **[At Which Training Stage Does Code Data Help LLMs Reasoning?](https://arxiv.org/abs/2309.16298)**. arXiv.

* Nguyen, Thuat, Chien Van Nguyen, Viet Dac Lai, et al. 2023.
  **[CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large Language Models in 167 Languages](https://arxiv.org/abs/2309.09400)**. arXiv.

* OpenAI Platform. n.d.
  **[Vector Embeddings](https://platform.openai.com/docs/guides/embeddings)**.

* Pemistahl. n.d.
  **[lingua-py](https://github.com/pemistahl/lingua-py)**.

* Penedo, Guilherme, Quentin Malartic, Daniel Hesslow, et al. 2023.
  **[The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only](https://arxiv.org/abs/2306.01116)**. arXiv.

* Salley, Columbus, and E. F. Codd. 1998.
  **[Providing OLAP to User-Analysts: An IT Mandate](https://scispace.com/pdf/providing-olap-to-user-analysts-an-it-mandate-1klqncel3i.pdf)**.

* Wang, Zige, Wanjun Zhong, Yufei Wang, et al. 2024.
  **[Data Management for Large Language Models: A Survey](https://arxiv.org/abs/2312.01700)**. arXiv.

* WARC Specifications. n.d.
  **[The WARC Format 1.0](https://iipc.github.io/warc-specifications/specifications/warc-format/warc-1.0/)**.

* Xu, Yipei, Dakuan Lu, Jiaqing Liang, et al. 2023.
  **[Source Prompt: Coordinated Pre-Training of Language Models on Diverse Corpora from Multiple Sources](https://arxiv.org/abs/2311.09732)**. arXiv.

* Xue, Fuzhao, Yao Fu, Wangchunshu Zhou, Zangwei Zheng, and Yang You. 2023.
  **[To Repeat or Not to Repeat: Insights from Scaling LLM Under Token-Crisis](https://arxiv.org/abs/2305.13230)**. arXiv.

* Yang, Rui, Michael Fu, Chakkrit Tantithamthavorn, et al. 2025.
  **[RAGVA: Engineering Retrieval Augmented Generation-Based Virtual Assistants in Practice](https://arxiv.org/abs/2502.14930)**. arXiv.

---

## 읽을거리

* Gao, Leo, Stella Biderman, Sid Black, et al. 2020.
  **[The Pile: An 800GB Dataset of Diverse Text for Language Modeling](https://arxiv.org/abs/2101.00027)**. arXiv.
